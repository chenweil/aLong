<!doctype html><html lang=en><head><script src="/aLong/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=aLong/livereload" data-no-instant defer></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><style>:root{--accent-color:#FF4D4D}</style><title>LLM_fine Tuning</title>
<meta name=description content="微调 fine-tuning 微调是一种监督学习过程,在这个过程中可以使用一组带标签的示例数据来更新LLM的权重.使其为特定任务生成良好完成的能力.
指令微调特别擅长提高模型在各种任务中的性能. 比如想让模型翻译能力增强,那就给他一些示例是包括翻译这句话之类的说明.即时完成示例允许模型学习生成遵循给定说明的响应.
微调 …"><meta name=keywords content='blog,aLong,blog.51ai.vip,LLM,AI'><meta property="og:url" content="http://localhost:1313/aLong/posts/llm_fine-tuning/"><meta property="og:type" content="website"><meta property="og:title" content="LLM_fine Tuning"><meta property="og:description" content="微调 fine-tuning 微调是一种监督学习过程,在这个过程中可以使用一组带标签的示例数据来更新LLM的权重.使其为特定任务生成良好完成的能力.
指令微调特别擅长提高模型在各种任务中的性能. 比如想让模型翻译能力增强,那就给他一些示例是包括翻译这句话之类的说明.即时完成示例允许模型学习生成遵循给定说明的响应.
微调 …"><meta property="og:image" content="http://localhost:1313/aLong/"><meta property="og:image:secure_url" content="http://localhost:1313/aLong/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="LLM_fine Tuning"><meta name=twitter:description content="微调 fine-tuning 微调是一种监督学习过程,在这个过程中可以使用一组带标签的示例数据来更新LLM的权重.使其为特定任务生成良好完成的能力.
指令微调特别擅长提高模型在各种任务中的性能. 比如想让模型翻译能力增强,那就给他一些示例是包括翻译这句话之类的说明.即时完成示例允许模型学习生成遵循给定说明的响应.
微调 …"><meta property="twitter:domain" content="http://localhost:1313/aLong/posts/llm_fine-tuning/"><meta property="twitter:url" content="http://localhost:1313/aLong/posts/llm_fine-tuning/"><meta name=twitter:image content="http://localhost:1313/aLong/"><link rel=canonical href=http://localhost:1313/aLong/posts/llm_fine-tuning/><link rel=stylesheet type=text/css href=/aLong/css/normalize.min.css media=print><link rel=stylesheet type=text/css href=/aLong/css/main.min.css><link id=dark-theme rel=stylesheet href=/aLong/css/dark.min.css><script src=/aLong/js/bundle.min.9a920d7dabdbad8363b6a0a94e29a9dfebdb7ee64cfcb193a0145e512ef2bdab.js integrity="sha256-mpINfavbrYNjtqCpTimp3+vbfuZM/LGToBReUS7yvas="></script></head><body><script>setThemeByUserPref()</script><header class=header><nav class=header-nav><div class=nav-title><a class=nav-brand href=http://localhost:1313/aLong/>aLong Blog</a></div><div class=nav-links><div class=nav-link><a href=http://localhost:1313/aLong/><span data-feather=home></span> Home</a></div><div class=nav-link><a href=http://localhost:1313/aLong/posts/>Posts</a></div><div class=nav-link><a href=http://localhost:1313/aLong/tags/>Tags</a></div><div class=nav-link><a href=http://localhost:1313/aLong/index.xml><span data-feather=rss></span></a></div><span class=nav-icons-divider></span><div class="nav-link dark-theme-toggle"><span class="sr-only dark-theme-toggle-screen-reader-target"></span>
<a><span class=theme-toggle-icon data-feather=moon></span></a></div><div class=nav-link id=hamburger-menu-toggle><span class="sr-only hamburger-menu-toggle-screen-reader-target">menu</span>
<a><span data-feather=menu></span></a></div><ul class="nav-hamburger-list visibility-hidden"><li class=nav-item><a href=http://localhost:1313/aLong/><span data-feather=home></span> Home</a></li><li class=nav-item><a href=http://localhost:1313/aLong/posts/>Posts</a></li><li class=nav-item><a href=http://localhost:1313/aLong/tags/>Tags</a></li><li class=nav-item><a href=http://localhost:1313/aLong/index.xml><span data-feather=rss></span></a></li><li class="nav-item dark-theme-toggle"><span class="sr-only dark-theme-toggle-screen-reader-target">theme</span>
<a><span class=theme-toggle-icon data-feather=moon></span></a></li></ul></div></nav></header><main id=content><div class="post container"><div class=post-header-section><h1>LLM_fine Tuning</h1><small role=doc-subtitle></small><p class=post-date>2024/08/15</p><ul class=post-tags><li class=post-tag><a href=http://localhost:1313/aLong/tags/llm>LLM</a></li><li class=post-tag><a href=http://localhost:1313/aLong/tags/ai>AI</a></li></ul></div><div class=post-content><h1 id=微调-fine-tuning>微调 fine-tuning</h1><p>微调是一种监督学习过程,在这个过程中可以使用一组带标签的示例数据来更新LLM的权重.使其为特定任务生成良好完成的能力.</p><p>指令微调特别擅长提高模型在各种任务中的性能.
<img src=https://s2.loli.net/2024/08/15/zdjLFeb17cpSwvO.png alt=image.png></p><p>比如想让模型翻译能力增强,那就给他一些示例是包括翻译这句话之类的说明.即时完成示例允许模型学习生成遵循给定说明的响应.</p><h2 id=微调大致步骤>微调大致步骤</h2><ol><li>准备训练数据,需要特定的格式. 也可以通过数据集+模版来处理使其既是模版又是数据集(指令数据集).</li><li>将数据集划分为训练验证和测试.然后使用计算出的损失来更新标准反向传播中的模型权重(standard backpropagation)。多批次重复操作.
<img src=https://s2.loli.net/2024/08/15/NnuGVBHyRJAmeSQ.png alt=image.png></li><li>更新完进行最终的性能评估.通过测试得出精度.
<img src=https://s2.loli.net/2024/08/15/7V1TbfgcANhPyk5.png alt=image.png></li><li>最终得到一个微调模型(Instruct LLM).
<img src=https://s2.loli.net/2024/08/15/4dINakbHTDw2WRJ.png alt=image.png></li></ol></div><div class=prev-next></div><svg id="btt-button" class="arrow-logo" height="1em" viewBox="0 0 384 512" onclick="scrollToTop()" title="Go to top"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6.0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9.0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9.0L7 329.7c-9.4-9.4-9.4-24.6.0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg>
<script>let backToTopButton=document.getElementById("btt-button");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?backToTopButton.style.display="block":backToTopButton.style.display="none"}function scrollToTop(){window.scrollTo(0,0)}</script></div></main><footer class=footer><span>&copy; 2024 aLong</span>
<span>Made with &#10084;&#65039; using <a target=_blank href=https://github.com/526avijitgupta/gokarna>Gokarna</a></span></footer></body></html>