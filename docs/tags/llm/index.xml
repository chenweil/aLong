<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on aLong blog</title>
    <link>http://localhost:1313/aLong/tags/llm/</link>
    <description>Recent content in LLM on aLong blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Aug 2024 13:39:15 +0800</lastBuildDate><atom:link href="http://localhost:1313/aLong/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM_fine Tuning</title>
      <link>http://localhost:1313/aLong/posts/llm_fine-tuning/</link>
      <pubDate>Thu, 15 Aug 2024 13:39:15 +0800</pubDate>
      
      <guid>http://localhost:1313/aLong/posts/llm_fine-tuning/</guid>
      <description>&lt;h1 id=&#34;微调-fine-tuning&#34;&gt;微调 fine-tuning&lt;/h1&gt;
&lt;p&gt;微调是一种监督学习过程,在这个过程中可以使用一组带标签的示例数据来更新LLM的权重.使其为特定任务生成良好完成的能力.&lt;/p&gt;
&lt;p&gt;指令微调特别擅长提高模型在各种任务中的性能.
&lt;img loading=&#34;lazy&#34; src=&#34;https://s2.loli.net/2024/08/15/zdjLFeb17cpSwvO.png&#34; alt=&#34;image.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;比如想让模型翻译能力增强,那就给他一些示例是包括翻译这句话之类的说明.即时完成示例允许模型学习生成遵循给定说明的响应.&lt;/p&gt;
&lt;h2 id=&#34;微调大致步骤&#34;&gt;微调大致步骤&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;准备训练数据,需要特定的格式. 也可以通过数据集+模版来处理使其既是模版又是数据集(指令数据集).&lt;/li&gt;
&lt;li&gt;将数据集划分为训练验证和测试.然后使用计算出的损失来更新标准反向传播中的模型权重(standard backpropagation)。多批次重复操作.
&lt;img loading=&#34;lazy&#34; src=&#34;https://s2.loli.net/2024/08/15/NnuGVBHyRJAmeSQ.png&#34; alt=&#34;image.png&#34;  /&gt;
&lt;/li&gt;
&lt;li&gt;更新完进行最终的性能评估.通过测试得出精度.
&lt;img loading=&#34;lazy&#34; src=&#34;https://s2.loli.net/2024/08/15/7V1TbfgcANhPyk5.png&#34; alt=&#34;image.png&#34;  /&gt;
&lt;/li&gt;
&lt;li&gt;最终得到一个微调模型(Instruct LLM).
&lt;img loading=&#34;lazy&#34; src=&#34;https://s2.loli.net/2024/08/15/4dINakbHTDw2WRJ.png&#34; alt=&#34;image.png&#34;  /&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
  </channel>
</rss>
